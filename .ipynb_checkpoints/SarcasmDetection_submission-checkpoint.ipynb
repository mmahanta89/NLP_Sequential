{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional,GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing column width to observe haedline\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target colum - is_sarcastic having values as 0 and 1\n",
    "- Headline column carries the headline of the article, these characters hold importent words that distinguishes the sarcastic words and serious words in headlines\n",
    "- Article_link column carries the link for the article, link details doesnt contain much additional info compared to headline but just the repeat of words to represent the link\n",
    "- Total 26,709 data points available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No null values found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing the article link column as its not adding value to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['article_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['is_sarcastic']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_sarcastic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can notice we have more of non sracastic data points compared to sarcastic\n",
    "- This is still not a very significant difference as we have a wide data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cleaning Headline column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headline'] = df['headline'].apply(lambda x: x.lower())\n",
    "df['headline'] = df['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setting up tokenizer and max words we will be using to speed up the model building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in df.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['headline'].values)\n",
    "X = tokenizer.texts_to_sequences(df['headline'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['is_sarcastic']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM + RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "history = model.fit(X_train, Y_train, epochs = 25, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_accuracy.png')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sarcasm_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"Non-Sarcasm_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['Chowkidar hi chor hai']\n",
    "headline = tokenizer.texts_to_sequences(headline)\n",
    "headline = pad_sequences(headline, maxlen=29, dtype='int32', value=0)\n",
    "\n",
    "sentiment = model.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"Non-sarcastic\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['unaware sons eats lipstick as lunch']\n",
    "headline = tokenizer.texts_to_sequences(headline)\n",
    "headline = pad_sequences(headline, maxlen=29, dtype='int32', value=0)\n",
    "\n",
    "sentiment = model.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"Non-sarcastic\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some more data preparation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re,string,unicodedata\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headline'] = df['headline'].apply(remove_stopwords)\n",
    "df['headline'] = df['headline'].apply(lambda x: x.lower())\n",
    "df['headline'] = df['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in df.headline.values:\n",
    "    words.append(i.split())\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences = words , vector_size=EMBEDDING_DIM , window = 5 , min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size\n",
    "#https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\n",
    "vocab_len = len(w2v_model.wv)\n",
    "print(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "#tokenizer = text.Tokenizer(num_words=max_fatures, split=' ') #keeping same as earier will update later\n",
    "tokenizer = text.Tokenizer(num_words=28000, split=' ') \n",
    "tokenizer.fit_on_texts(words)\n",
    "tokenized_train = tokenizer.texts_to_sequences(words)\n",
    "x = sequence.pad_sequences(tokenized_train, maxlen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    vocab_size = len(vocab) + 1\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model.wv[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=20, trainable=True))\n",
    "#LSTM \n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.3 , dropout = 0.3,return_sequences = True)))\n",
    "model.add(Bidirectional(GRU(units=32 , recurrent_dropout = 0.1 , dropout = 0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "del embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, df.is_sarcastic , test_size = 0.3 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128 , validation_data = (x_test,y_test) , epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100)\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(x_test,y_test)[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(df['headline'], df['is_sarcastic'], test_size=0.2, random_state=0)\n",
    "\n",
    "print(train_sentences.shape)\n",
    "print(val_sentences.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad\n",
    "vocab_size = 10000\n",
    "oov_token = '<00V>'\n",
    "max_length = 120\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "embedding_dim = 16\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer with GlobalAveragePooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(train_padded, \n",
    "                    train_labels, \n",
    "                    validation_data=(val_padded, val_labels), \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer with Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "history_flatten = model2.fit(train_padded, \n",
    "                    train_labels, \n",
    "                    validation_data=(val_padded, val_labels), \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()\n",
    "history_lstm = model_lstm.fit(train_padded, \n",
    "                    train_labels, \n",
    "                    validation_data=(val_padded, val_labels), \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi layer bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul_lstm = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mul_lstm.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model_mul_lstm.summary()\n",
    "history_mul_lstm = model_mul_lstm.fit(train_padded, \n",
    "                    train_labels, \n",
    "                    validation_data=(val_padded, val_labels), \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep with GLove 200d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/Sarcasm_Headlines_Dataset.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    phrase=str(phrase)\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#https://spacy.io/usage/models\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def preprocessing(text):\n",
    "  text = text.replace('#','')\n",
    "  text = decontracted(text)\n",
    "  text = re.sub('\\S*@\\S*\\s?','',text)\n",
    "  text = re.sub('http[s]?:(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text)\n",
    "\n",
    "  token=[]\n",
    "  result=''\n",
    "  text = re.sub('[^A-z]', ' ',text.lower())\n",
    "  \n",
    "  text = nlp(text)\n",
    "  for t in text:\n",
    "    if not t.is_stop and len(t)>2:  \n",
    "      token.append(t.lemma_)\n",
    "  result = ' '.join([i for i in token])\n",
    "\n",
    "  return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.text = df.headline.apply(lambda x : preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['headline'] = df['headline'].apply(lambda x: x.lower())\n",
    "df['headline'] = df['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))\n",
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for tweet in tqdm(df['headline']):\n",
    "        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_dict={}\n",
    "with open('data/glove.6B.200d.txt','r',encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN=40\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "tweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,200))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    emb_vec=embedding_dict.get(word)\n",
    "    if emb_vec is not None:\n",
    "        embedding_matrix[i]=emb_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Single layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D,Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "model=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,200,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64,dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "filepath=\"weights-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=30)\n",
    "callbacks_list = [checkpoint,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=df.iloc[:,:]\n",
    "X=tweet_pad[:tweet.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,tweet['is_sarcastic'].values,test_size=0.2)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=25,validation_data=(X_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#history=model.fit(X_train,y_train,batch_size=100,epochs=100,validation_data=(X_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headline = ['\\'nice to meet you,\\' coworkers tell new employee they\\'ve studied online for hours']\n",
    "#headline = pd.DataFrame(headline)\n",
    "#headline = preprocessing(headline)\n",
    "\n",
    "headline = ['\\'nice to meet you,\\' coworkers tell new employee they\\'ve studied online for hours']\n",
    "sequences=tokenizer_obj.texts_to_sequences(headline)\n",
    "\n",
    "headline=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\n",
    "\n",
    "sentiment = model.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(sentiment < 0.45):\n",
    "    print(\"Non-sarcastic\")\n",
    "else:\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headline = ['\\'nice to meet you,\\' coworkers tell new employee they\\'ve studied online for hours']\n",
    "#headline = pd.DataFrame(headline)\n",
    "#headline = preprocessing(headline)\n",
    "\n",
    "headline = ['dog is smoking hot']\n",
    "sequences=tokenizer_obj.texts_to_sequences(headline)\n",
    "\n",
    "headline=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\n",
    "\n",
    "sentiment = model.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(sentiment < 0.45):\n",
    "    print(\"Non-sarcastic\")\n",
    "else:\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib \n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "\n",
    "joblib.dump(model, 'model_embd_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi layer bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,200,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model2.add(embedding)\n",
    "model2.add(SpatialDropout1D(0.2))\n",
    "model2.add(Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(32,dropout=0.2, recurrent_dropout=0.2)))\n",
    "#model2.add(Dense(24, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=0.001)\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history=model2.fit(X_train,y_train,batch_size=100,epochs=25,validation_data=(X_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,200,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model2.add(embedding)\n",
    "model2.add(SpatialDropout1D(0.5))\n",
    "#model2.add(Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2)))\n",
    "#model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=0.001)\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=model2.fit(X_train,y_train,batch_size=100,epochs=25,validation_data=(X_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib \n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "\n",
    "joblib.dump(model2, 'model_embd_3.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['nice to meet you, coworkers tell new employee they\\'ve studied online for hours']\n",
    "headline = pd.DataFrame(headline)\n",
    "headline = preprocessing(headline)\n",
    "\n",
    "sequences=tokenizer_obj.texts_to_sequences(headline)\n",
    "\n",
    "headline=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\n",
    "\n",
    "sentiment = model2.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(sentiment < 0.1):\n",
    "    print(\"Non-sarcastic\")\n",
    "else:\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['Silence is golden. Duct tape is silver.']\n",
    "headline = pd.DataFrame(headline)\n",
    "headline = preprocessing(headline)\n",
    "\n",
    "sequences=tokenizer_obj.texts_to_sequences(headline)\n",
    "\n",
    "headline=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\n",
    "\n",
    "sentiment = model2.predict(headline,batch_size=1,verbose = 2)[0]\n",
    "if(sentiment < 0.1):\n",
    "    print(\"Non-sarcastic\")\n",
    "else:\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with multiple models and results we can observe that increasing the layers not necessarily incresing the prediction capacity but sometimes decreasing it as well if not properly fine tuned.\n",
    "- We were able to acheieve close to 83% accuracy for test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the words in the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install stylecloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylecloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylecloud.gen_stylecloud(file_path='data/Sarcasm_Headlines_Dataset.json',icon_name='fas fa-apple-alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open('stylecloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
